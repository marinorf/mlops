# ğŸ¤– MLâ€‰Ops Workflow for Breast Cancer Wisconsin

This repository implements a full ML workflow for the Breast Cancer Wisconsin dataset, developed as part of the MLâ€‰Operations course at EWHA University. All stepsâ€”from data ingestion through model training and evaluationâ€”are managed through a Makefile.

---

## âš™ï¸ Workflow Overview

1. **Data Management**  
2. **Preprocessing**  
3. **Model Training**  
4. **Model Evaluation**  
5. **Dependency Management**

---

### 1. Data Management

#### Download Data  
Fetch the Breast Cancer Wisconsin dataset from Kaggle and save it as `data/raw.csv`.

<blockquote>
<pre>
make download-data
</pre>
</blockquote>

> **Prerequisite:** You must have a valid `kaggle.json` in `~/.kaggle/` (or set `KAGGLE_CONFIG_DIR`) for Kaggle API authentication.

---

### 2. Preprocessing

#### Preprocess Raw Data  
Clean the raw CSV, engineer features, and split into train/test sets:
- `data/X_train.csv`
- `data/y_train.csv`
- `data/X_test.csv`
- `data/y_test.csv`

<blockquote>
<pre>
make preprocess-data
</pre>
</blockquote>

---

### 3. Model Training

#### Train CatBoost Model  
Train a CatBoost classifier on the processed training data and save the model artifact under `models/`.

<blockquote>
<pre>
make train-catboost
</pre>
</blockquote>

#### Train MLJAR AutoML Model  
Launch an AutoML run with MLJARâ€‘Supervised, storing results in `models/AutoML_results/`.

<blockquote>
<pre>
make train-MLJar
</pre>
</blockquote>

---

### 4. Model Evaluation

#### Evaluate All Models  
Compute accuracy, precision, recall, F1, confusion matrices, and output predictions under `evaluate/`.

<blockquote>
<pre>
make evaluate-models
</pre>
</blockquote>

---

### 5. Dependency Management

#### Install Python Packages  
Install all required libraries as pinned in `requirements.txt`.

<blockquote>
<pre>
make install
</pre>
</blockquote>

---

## ğŸ“‚ Repository Structure
```
.
â”œâ”€â”€ Makefile                     # Automates the workflow
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ data/                        # Raw & preprocessed datasets
â”‚   â”œâ”€â”€ raw.csv
â”‚   â”œâ”€â”€ processed/
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â””â”€â”€ y_test.csv
â”œâ”€â”€ models/                      # Model python files and saved models
â”‚   â”œâ”€â”€ best_catboost_model.cbm
â”‚   â”œâ”€â”€ catboost_model.py
â”‚   â”œâ”€â”€ MLJar_model.py
â”‚   â””â”€â”€ AutoML_results/         
â”œâ”€â”€ scripts/                     # Pipeline scripts
â”‚   â””â”€â”€ preprocess.py            # Data cleaning & train/test seperation
â”œâ”€â”€ evaluate/                    # Model evaluation scripts
â”‚   â”œâ”€â”€ evaluate_catboost.py
â”‚   â””â”€â”€ evaluate_MLJar.py
```

### ğŸ“ Notes
Testing - tests of functions are not yet implemented.

Kaggle Authentication - Ensure your Kaggle API token (kaggle.json) is in ~/.kaggle/.